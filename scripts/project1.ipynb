{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required ML methods\n",
    "\n",
    "1. *** least_squares_GD (y, tx, inital_w, gamma, max_iters) ***\n",
    "Linear regression using gradient descent \n",
    "\n",
    "2. *** least_squares_SGD(y, tx, initial_w, gamma, max_iters) ***\n",
    "Linear regression using stochastic gradient descent \n",
    "\n",
    "3. *** least_squares(y, tx) ***\n",
    "Least squares regression using normal equations\n",
    "\n",
    "4. *** ridge_regression(y, tx, lambda_) ***\n",
    "Ridge regression using normal equations\n",
    "\n",
    "5. *** logistic_regression(y, tx, initial_w, gamma, max_iters) ***\n",
    "Logistic regression using gradient descent or SGD \n",
    "\n",
    "6. *** reg_logistic_regression(y, tx, lambda_, initial_w, gamma, max_iters) ***\n",
    "Regularized  logistic  regression  using  gradient  descent or SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import math\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from helpers import *\n",
    "\n",
    "DATA_TRAIN_PATH = '../data/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to obtain get column names of data, and obtain its positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DER_mass_MMC', 'DER_mass_transverse_met_lep', 'DER_mass_vis',\n",
       "       'DER_pt_h', 'DER_deltaeta_jet_jet', 'DER_mass_jet_jet',\n",
       "       'DER_prodeta_jet_jet', 'DER_deltar_tau_lep', 'DER_pt_tot',\n",
       "       'DER_sum_pt', 'DER_pt_ratio_lep_tau', 'DER_met_phi_centrality',\n",
       "       'DER_lep_eta_centrality', 'PRI_tau_pt', 'PRI_tau_eta',\n",
       "       'PRI_tau_phi', 'PRI_lep_pt', 'PRI_lep_eta', 'PRI_lep_phi',\n",
       "       'PRI_met', 'PRI_met_phi', 'PRI_met_sumet', 'PRI_jet_num',\n",
       "       'PRI_jet_leading_pt', 'PRI_jet_leading_eta', 'PRI_jet_leading_phi',\n",
       "       'PRI_jet_subleading_pt', 'PRI_jet_subleading_eta',\n",
       "       'PRI_jet_subleading_phi', 'PRI_jet_all_pt'], \n",
       "      dtype='<U27')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_x = np.genfromtxt(DATA_TRAIN_PATH, delimiter=\",\", skip_header=0, dtype=str)\n",
    "columns = str_x[0, 2:]\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DER_deltaeta_jet_jet': 4,\n",
       " 'DER_deltar_tau_lep': 7,\n",
       " 'DER_lep_eta_centrality': 12,\n",
       " 'DER_mass_MMC': 0,\n",
       " 'DER_mass_jet_jet': 5,\n",
       " 'DER_mass_transverse_met_lep': 1,\n",
       " 'DER_mass_vis': 2,\n",
       " 'DER_met_phi_centrality': 11,\n",
       " 'DER_prodeta_jet_jet': 6,\n",
       " 'DER_pt_h': 3,\n",
       " 'DER_pt_ratio_lep_tau': 10,\n",
       " 'DER_pt_tot': 8,\n",
       " 'DER_sum_pt': 9,\n",
       " 'PRI_jet_all_pt': 29,\n",
       " 'PRI_jet_leading_eta': 24,\n",
       " 'PRI_jet_leading_phi': 25,\n",
       " 'PRI_jet_leading_pt': 23,\n",
       " 'PRI_jet_num': 22,\n",
       " 'PRI_jet_subleading_eta': 27,\n",
       " 'PRI_jet_subleading_phi': 28,\n",
       " 'PRI_jet_subleading_pt': 26,\n",
       " 'PRI_lep_eta': 17,\n",
       " 'PRI_lep_phi': 18,\n",
       " 'PRI_lep_pt': 16,\n",
       " 'PRI_met': 19,\n",
       " 'PRI_met_phi': 20,\n",
       " 'PRI_met_sumet': 21,\n",
       " 'PRI_tau_eta': 14,\n",
       " 'PRI_tau_phi': 15,\n",
       " 'PRI_tau_pt': 13}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_idx = {}\n",
    "for i in range(len(columns)):\n",
    "    col_idx[columns[i]] = i\n",
    "col_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data\n",
    "\n",
    "We throw away data whose DER_mass_MMC is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# throw DER_mass_MMC < 0\n",
    "X = tX\n",
    "valid_mass_idx = np.where(tX[:, col_idx['DER_mass_MMC']] != -999)[0]\n",
    "valid_mass_dat = X[valid_mass_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211886, 30)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_mass_dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace other -999 with 0\n",
    "valid_dat = valid_mass_dat\n",
    "for i in range(valid_mass_dat.shape[1]):\n",
    "    idx = np.where(valid_dat[:, i] == -999)[0]\n",
    "    valid_dat[idx, i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# delete features : \n",
    "# variables prefixed with DER (for DERived) are quantities computed from the primitive features, which were selected by  the physicists of ATLAS\n",
    "# throw out DER_... except DER_mass_MMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add polynomial features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# General gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# general gradient descent\n",
    "def gradient_descent(y, tx, initial_x, gamma, max_iters,\n",
    "                     compute_gradient, compute_loss):\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    \n",
    "    for n_iter in range(max_iters):\n",
    "        gradient = compute_gradient(y, tx, w)\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        w = w - gamma * gradient\n",
    "        # print(loss)\n",
    "        \n",
    "        losses.append(loss)\n",
    "    \n",
    "    return w, losses[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, gamma, max_iters, seed,\n",
    "                                compute_gradient, compute_loss):\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    \n",
    "    num_batches = math.floor(y.shape[0] / batch_size) \n",
    "    batches = batch_iter(y, tx, seed, batch_size, num_batches)\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        batch_y, batch_tx = next(batches)\n",
    "        gradient = compute_gradient(batch_y, batch_tx, w)\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        #print(loss)\n",
    "        w = w - gamma * gradient\n",
    "        \n",
    "        losses.append(loss)\n",
    "        \n",
    "    return w, losses[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression using gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: perhaps import it instead of copy?\n",
    "def calculate_mse(e):\n",
    "    \"\"\"Calculate the mse for vector e.\"\"\"\n",
    "    return 1/2*np.mean(e**2)\n",
    "\n",
    "def calculate_mae(e):\n",
    "    \"\"\"Calculate the mae for vector e.\"\"\"\n",
    "    return np.mean(np.abs(e))\n",
    "\n",
    "def compute_loss_mse(y, tx, w):\n",
    "    \"\"\"Calculate the loss using mse \"\"\"\n",
    "    e = y - tx.dot(w)\n",
    "    return calculate_mse(e)\n",
    "\n",
    "def compute_gradient_mse(y, tx, w):\n",
    "    \"\"\" compute the gradient associated to the MSE cost function\"\"\"\n",
    "    e = y - (tx @ w)\n",
    "    return -1/y.shape[0] * (tx.T @ e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares_GD(y, tx, initial_w, gamma, max_iters):\n",
    "    return gradient_descent(y, tx, initial_w, gamma, max_iters,\n",
    "                            compute_gradient_mse, compute_loss_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_iters = 100\n",
    "gamma = 1e-7\n",
    "initial_w = np.zeros(tX.shape[1])\n",
    "\n",
    "w_linear_gd, loss_linear_gd = least_squares_GD(y, tX, initial_w, gamma, max_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41560782934140184"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_linear_gd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression using stochastic gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares_SGD(y, tx, initial_w, gamma, max_iters):\n",
    "    batch_size = y.shape[0]//2\n",
    "    seed = 3\n",
    "    \n",
    "    return stochastic_gradient_descent(y, tx, initial_w, batch_size, gamma, max_iters,\n",
    "                                       seed, compute_gradient_mse, compute_loss_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_iters = 100\n",
    "gamma = 1e-8\n",
    "initial_w = np.zeros(tX.shape[1])\n",
    "\n",
    "w_linear_sgd, loss_linear_sgd = least_squares_SGD(y, tX, initial_w, gamma, max_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43947820815603295"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_linear_sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares regression using normal equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares(y, tx):\n",
    "    w = (np.linalg.inv(tx.T @ tx) @ tx.T @ y)\n",
    "    loss = compute_loss_mse(y, tx, w)\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_ls, loss_ls = least_squares(y, tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33968680990826089"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression using normal equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    w = np.linalg.inv(tx.T @ tx + lambda_ * np.identity(tx.shape[1])) @ tx.T @ y\n",
    "    loss = compute_loss_mse(y, tx, w)\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lamb = 23\n",
    "w_ridge, loss_ridge = ridge_regression(y, tX, lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33968793894774219"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    \"\"\"apply sigmoid function on t.\"\"\"\n",
    "    return 1 / (1 + np.exp(-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss_log(y, tx, w):\n",
    "    \"\"\"compute cost by negative log likelihood.\"\"\"\n",
    "    xw = tx @ w\n",
    "    return np.sum(np.log(1 + np.exp(xw)) - y * xw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_gradient_log(y, tx, w):\n",
    "    \"\"\"compute the gradient of loss.\"\"\"\n",
    "    xw = tx @ w\n",
    "    return tx.T @ (np.apply_along_axis(sigmoid, 0, xw) - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## using gradient descent\n",
    "def logistic_regression(y, tx, initial_w, gamma, max_iters):\n",
    "    return gradient_descent(y, tx, initial_w, gamma, max_iters,\n",
    "                            compute_gradient_log, compute_loss_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_iters = 100\n",
    "gamma = 1e-14\n",
    "initial_w = np.zeros(tX.shape[1])\n",
    "\n",
    "w_log, loss_log = logistic_regression(y, tX, initial_w, gamma, max_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23641.840065980567"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized  logistic  regression  using  gradient  descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss_rlog(y, tx, w, lambda_):\n",
    "    return compute_loss_log(y, tx, w) + lambda_ * w.T @ w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_gradient_rlog(y, tx, w, lambda_):\n",
    "    return compute_gradient_log(y, tx, w) + 2 * lambda_ * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reg_logistic_regression(y, tx, lambda_, initial_w, gamma, max_iters):\n",
    "    compute_gradient = partial(compute_gradient)\n",
    "    compute_loss = partial(compute_loss_logistic, lambda_ = lambda_)\n",
    "    return gradient_descent(y, tx, initial_w, gamma, max_iters,\n",
    "                            compute_gradient, compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_iters = 100\n",
    "gamma = 1e-14\n",
    "initial_w = np.zeros(tX.shape[1])\n",
    "\n",
    "w_rlog, loss_rlog = logistic_regression(y, tX, initial_w, gamma, max_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23641.840065980567"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_rlog"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3k]",
   "language": "python",
   "name": "conda-env-py3k-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
