{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required ML method\n",
    "\n",
    "1. *** least_squares_GD (y, tx, inital_w, gamma, max_iters) ***\n",
    "Linear regression using gradient descent \n",
    "\n",
    "2. *** least_squares_SGD(y, tx, initial_w, gamma, max_iters) ***\n",
    "Linear regression using stochastic gradient descent \n",
    "\n",
    "3. *** least_squares(y, tx) ***\n",
    "Least squares regression using normal equations\n",
    "\n",
    "4. *** ridge_regression(y, tx, lambda_) ***\n",
    "Ridge regression using normal equations\n",
    "\n",
    "5. *** logistic_regression(y, tx, initial_w, gamma, max_iters) ***\n",
    "Logistic regression using gradient descent or SGD \n",
    "\n",
    "6. *** reg_logistic_regression(y, tx, lambda_, initial_w, gamma, max_iters) ***\n",
    "Regularized  logistic  regression  using  gradient  descent or SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "\n",
    "DATA_TRAIN_PATH = '../data/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# copied from costs.py\n",
    "# TODO: perhaps import it instead of copy?\n",
    "\n",
    "def calculate_mse(e):\n",
    "    \"\"\"Calculate the mse for vector e.\"\"\"\n",
    "    return 1/2*np.mean(e**2)\n",
    "\n",
    "\n",
    "def calculate_mae(e):\n",
    "    \"\"\"Calculate the mae for vector e.\"\"\"\n",
    "    return np.mean(np.abs(e))\n",
    "\n",
    "\n",
    "def compute_loss(y, tx, w):\n",
    "    \"\"\"Calculate the loss using mse \"\"\"\n",
    "    e = y - tx.dot(w)\n",
    "    return calculate_mse(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression using gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\" compute the gradient associated to the MSE cost function\"\"\"\n",
    "    # return tx.T.dot( sigmoid(tx.dot(w)) - y.reshape((tx.shape[0],1)) )\n",
    "    e = y - (tx @ w)\n",
    "    return -1/y.shape[0] * (tx.T @ e)\n",
    "\n",
    "\n",
    "def least_squares_GD(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"\n",
    "    Gradient descent algorithm using the MSE cost function\n",
    "    \n",
    "    Params:\n",
    "        y (1D-array): training values\n",
    "        tx (2D-array): each row contains the data associated to a sample.\n",
    "                    each column contains all the sample value for a feature\n",
    "        initial_w (1D-array): the initial weight vector\n",
    "        max_iters (int): maximum number of iterations to run\n",
    "        gamma (float): step size   \n",
    "\n",
    "    Returns:\n",
    "        w (1D-array): the last weight vector\n",
    "        loss (float): the last loss value\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    losses.append(compute_cost(y, tx, w))\n",
    "    \n",
    "    \n",
    "    for n_iter in range(max_iters):\n",
    "        # compute one step of gradient descent\n",
    "        grad = compute_gradient(y, tx, w)\n",
    "        w = w - gamma * grad\n",
    "        loss = compute_cost(y, tx, w)\n",
    "\n",
    "        # store results\n",
    "        losses.append(loss)\n",
    "\n",
    "    return w, losses[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_iters = 1000\n",
    "gamma = 1e-7\n",
    "initial_w = np.zeros(tX.shape[1])\n",
    "\n",
    "w, loss = least_squares_GD(y, tX, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3k]",
   "language": "python",
   "name": "conda-env-py3k-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
